# Databricks notebook source
# MAGIC %md
# MAGIC # Airline Delays
# MAGIC ## MIDS W261 Final Project
# MAGIC #### *Laura Herman, Michael Hubert, Robin Lashof-Regas, and Steven Leung*

# COMMAND ----------

# MAGIC %md
# MAGIC ## Question Formulation and Prior Research
# MAGIC According to the Federal Aviation Administration (FAA) flight delays cost airlines and passengers over twenty eight billion dollars in 2018 [NEED SOURCE]. For airlines this cost can be attributed to (NOT SURE ABOUT THESE REASONS) fuel(?), employee overtime, maintenance(?), loss of trust in the airline, and rebooking cost. For passengers this cost can be attributed to loss of productivity due to missed time at work, lost wages due to missing work, and overtime wages due to additional travel time. Some of these costs can be greatly reduced or eliminated if an airline could know in advance whether or not a given flight will be delayed. The purpose of this project is to predict whether a given flight will be delayed by 15 minutes or more, at least 2 hours before the scheduled departure. 
# MAGIC 
# MAGIC To accomplish this task we use data provided by the U.S. Department of Transportation (DOT) for passenger flight data between 2015 and 2019. We also augment this dataset with weather data from US weather stations provided by the National Oceanic and Atmospheric Administration over the same time period. We treat this problem as a classification problem with the goal to predict the value of the outcome variable labeled as *DEP_DEL15* in the DOT airlines dataset which indicates whether a flight was delayed by at least 15 minutes (aligning with the FAA definition of a delayed flight [NEED SOURCE]). As we perform our analysis our primary evaluation metric will be recall as the main business driver is to find as many of the delayed flights as possible as the impact is relatively less if we inacurately predict that an on-time flight will be delayed. That said, we want to make sure our model is not overfitting to this metric (for example predicting every flight as delayed), so we will also incorporate accuracy into our evaluation metrics.
# MAGIC 
# MAGIC This is not a novel research question. Most studies incorporate airline and weather data as we have, while more use novel approaches to data collection such as IoT sensors (FOR? - NEED SOURCE). The most common models used for this task include Random Forest, K-Nearest Neighbors, and Neural Networks. We explore some of these options in the sections that follow. The best results we were able to find on this topic were those from L. Belcastro et al. where they achieved 86% accuracy with 87% recall using a Random Forest model. One of the key takeaways from this study was their method of categorizing delays as "Chain Delays" (delays caused by previous delays such as late-arriving aircraft) and "Root Cause Delays" (cause of original delay such as weather or maintenance). The following plot from the same study breaks down these delays:
# MAGIC 
# MAGIC [INSERT IMAGE VIA METHOD SUCH AS https://forums.databricks.com/questions/29012/how-to-show-an-image-in-a-notebook-using-html.html]
# MAGIC 
# MAGIC In our work we build on this concept, providing a number of novel features in order to capture these concepts to influence our models. We begin with some exploratory data analysis where we justify our feature engineering/selection and verify some of our assumptions and processing of the incoming data. Next we discuss the feature engineering we performed to capture the chain and root cause delay concepts mentioned above. Following this we show a few of the base models we tried and motivate our decision to focus on Random Forest. After this we deep dive into our model as well as some of the mathematical formulation of Random Forest itself. Finally, we discuss some key takeaways from this work, next steps, and briefly discuss how the analysis presented showcases what we've learned in the W261 course.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Exploratory Data Analysis
# MAGIC 
# MAGIC With our exploratory data analysis we had two primary goals:
# MAGIC 1. Understand the columns available including any missing or invalid data as well as the format of that data.
# MAGIC 2. Determine the distribution of relevant columns and their relationship with the outcome variable in order to give hints towards our feature engineering.
# MAGIC 
# MAGIC The obvious first step is to read in our data which is accomplished through the code below:

# COMMAND ----------

# package imports
from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, NullType, ShortType, DateType, BooleanType, BinaryType
from pyspark.sql import SQLContext
from pyspark.sql import types
from pyspark.sql.functions import col, lag, udf, to_timestamp, monotonically_increasing_id
import pyspark.sql.functions as f
from pyspark.sql.window import Window
from pandas.tseries.holiday import USFederalHolidayCalendar
from datetime import datetime, timedelta
from pyspark.ml.feature import IndexToString, StringIndexer, OneHotEncoder, VectorAssembler, Bucketizer, StandardScaler
import pandas as pd
from pyspark.ml.linalg import Vectors
from pyspark.ml.stat import Correlation
import matplotlib.pyplot as plt

# COMMAND ----------

# initialize the sql context
sqlContext = SQLContext(sc)

# COMMAND ----------

# input data paths
weather_data_path = "dbfs:/mnt/mids-w261/datasets_final_project/weather_data/weather20*.parquet"
airlines_data_path = "dbfs:/mnt/mids-w261/datasets_final_project/parquet_airlines_data/20*.parquet"

# COMMAND ----------

# read in raw data
airlines = spark.read.option("header", "true").parquet(airlines_data_path) # full airline dataset

# register temp view
airlines.createOrReplaceTempView("airlines")

# COMMAND ----------

# MAGIC %md
# MAGIC ### Airline EDA
# MAGIC One of the first things we looked at was the distribution of our outcome variable `dep_del15`:

# COMMAND ----------

display(sqlContext.sql("SELECT dep_del15, count(*) AS flights FROM airlines GROUP BY dep_del15 ORDER BY count(*) desc"))

# COMMAND ----------

# MAGIC %md
# MAGIC As we can see the distribution is uneven with an approximately 20/80 split between flights that were delayed and those that weren't. In the proceeding sections we describe our methods for handling this using over-sampling or class weight variables.
# MAGIC 
# MAGIC We also notice that there are a little over 1% nulls. A little more analysis (ommitted here for brevity) shows that of these 477,296 flights:
# MAGIC 
# MAGIC - 472,552 of them were cancelled - we choose to ignore these in our training set because, for the purposes of our model, we are not diving into the various `cancellation_code`s and therefore do not have data on what caused the cancellation (i.e. was it due to not enough passengers, weather, etc.). This is a potential next step that we could come back to in the future. For our test and validation sets we consider these flights as incorrectly predicted regardless of whether we predicted them as delayed or not.
# MAGIC - 4,739 of them had `crs_dep_time` (scheduled departure time) equal to `dep_time` (actual departure time). This seems to be a bug in the data because the rest of the fields for these flights appear normal. For this reason we manually set the `dep_del15` column to 0 for these flights.
# MAGIC - The final 5 flights are marked as `diverted` and have additional records for the new flight number assigned to those airplanes from the same departure airport. For this reason we choose to ignore them in our training set, and as above mark them as incorrect predictions regardless of our predicted class.

# COMMAND ----------

# MAGIC %md
# MAGIC The next thing we explored in the flights data was the timing of flights. We guess that, as with flights themselves, delays will have a clear time dependency. This time dependency may come in many different forms - hour of the day, day of the week, day of the year, etc. Below we explore these distributions via plots of the ratio of flights to delays:

# COMMAND ----------

# Distribution of flights and delays by scheduled departure time of day
display(sqlContext.sql("SELECT ROUND(crs_dep_time, -2) AS hour, SUM(dep_del15) / COUNT(*) AS delay_pct FROM airlines GROUP BY hour ORDER BY hour"))

# Distribution of flights and delays by day of week
display(sqlContext.sql("SELECT day_of_week, SUM(dep_del15) / COUNT(*) AS delay_pct FROM airlines GROUP BY day_of_week ORDER BY day_of_week"))

# Distribution of flights and delays by day of year
display(sqlContext.sql("SELECT CAST(DATE_FORMAT(fl_date, 'D') AS INT) AS day_of_year, SUM(dep_del15) / COUNT(*) AS delay_pct FROM airlines GROUP BY day_of_year ORDER BY day_of_year"))

# COMMAND ----------

# MAGIC %md
# MAGIC We can see from above that the clearest correllation exists with the hour of the day because, while the number of flights is relatively constant for most of the day, the number of delays increases substantially as the day progresses. This makes sense given our preliminary research discussed in the first section in relation to "chain delays". As the day progresses it is more likely that there was a previous delay that may be affecting this flight causing more chain delays.
# MAGIC 
# MAGIC It is somewhat surprising to us that we do not see a strong signal based on the day of the week, but this is useful info nonetheless to help influence our choice of features.
# MAGIC 
# MAGIC Finally, it does seem like the day of year could be useful. While for the most part the pattern of delays matches the pattern in the number of flights (relatively constant ratio), there does seem to be an increase in the flights to delays ratio in both the summer and winter months. This makes some sense because these months involve both an increase in the number of flights as well as an increase in the amount of inclement weather in most regions.

# COMMAND ----------

# MAGIC %md
# MAGIC The final relationship that we found useful to explore in the flights data relates to the airport. Building on our concepts of root cause delays and chain delays we would think that on a given day with a significant number of delays we are likely to see a large spike compared to days with a more regular number of delays. This is because as the number of delays on a given day increases, it is more likely that the day in question has a root cause delay such as weather or an airport-wide issue. In addition, as we have more delays on a given day the number of chain delays also increases.
# MAGIC 
# MAGIC To understand this it is useful to compare a single airport for a single year as compared to all other airports in the same year. In this case we look at Chicago (ORD) for the year of 2015:

# COMMAND ----------

# delays by day of year for a single year and airport
display(sqlContext.sql("""
SELECT
  CAST(DATE_FORMAT(fl_date, 'D') AS INT) AS day_of_year,
  SUM(CASE WHEN origin = 'ORD' THEN dep_del15 ELSE 0 END) / SUM(CASE WHEN origin = 'ORD' THEN 1 ELSE 0 END) AS ord_delay_pct,
  SUM(CASE WHEN origin <> 'ORD' THEN dep_del15 ELSE 0 END) / SUM(CASE WHEN origin <> 'ORD' THEN 1 ELSE 0 END) AS other_delay_pct
FROM airlines
WHERE
  year = '2015'
GROUP BY day_of_year
ORDER BY day_of_year"""))

# COMMAND ----------

# MAGIC %md
# MAGIC From the above plot we can see that our theory holds some weight. For example on January 4th ORD had over 70% of flights delayed whereas the national average was 44% and on February 26th ORD had almost 74% delays whereas the national average was only around 30%. This makes it clear that we need to capture airport-level statistics in our feature engineering (which we discuss further in the following section).

# COMMAND ----------

# MAGIC %md
# MAGIC #### Weather EDA
# MAGIC 
# MAGIC To get an understanding of what the weather data looks like, let's take a look at some example rows:

# COMMAND ----------

display(weather.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC As we can see there is a vast majority of columns with blanks for these example rows. In general as we look at the weather data we see this same trend - many of the columns are exremely specific and technical details around a single (relatively rare) weather condition. In addition, many weather stations do not capture all of the data fields.
# MAGIC 
# MAGIC Looking at some of the other columns that we would think would be useful such as visibility, wind details, temperature, dew point, etc. we see that they are mostly in a coded format that will require us to parse out the values we need (discussed further in the following section).
# MAGIC 
# MAGIC In order to perform some additional EDA on the weather data we read in our saved files that contain some parsed features joined to the flights data:

# COMMAND ----------

final_project_path = "dbfs:/mnt/mids-w261/group_5/"
train_data_output_path_one_hot = final_project_path + "training_data_output/train_one_hot.parquet"

# read in parsed data
joined = spark.read.option("header", "true").parquet(train_data_output_path_one_hot)

# register temp views
joined.createOrReplaceTempView("joined")

# COMMAND ----------

joined.printSchema()

# COMMAND ----------

# MAGIC %md
# MAGIC Some of the features we believe will be the most important are wind speed, visibility, current atmospheric conditions (categorical), and current rain and snow depths. Let's examine these distributions with departure delays:

# COMMAND ----------

# delays by day of year for a single year and airport
display(sqlContext.sql("""
SELECT
  origin_WND_speed_rate,
  SUM(dep_del15) / COUNT(*) as pct_delays
FROM joined
GROUP BY origin_WND_speed_rate
ORDER BY origin_WND_speed_rate"""))

display(sqlContext.sql("""
SELECT
  origin_VIS_distance,
  SUM(dep_del15) / COUNT(*) as pct_delays
FROM joined
GROUP BY origin_VIS_distance
ORDER BY origin_VIS_distance"""))

display(sqlContext.sql("""
SELECT
  origin_aw1_automated_atmospheric_condition,
  SUM(dep_del15) / COUNT(*) as pct_delays
FROM joined
GROUP BY origin_aw1_automated_atmospheric_condition
ORDER BY origin_aw1_automated_atmospheric_condition"""))

display(sqlContext.sql("""
SELECT
  origin_aj1_snow_depth,
  SUM(dep_del15) / COUNT(*) as pct_delays
FROM joined
GROUP BY origin_aj1_snow_depth
ORDER BY origin_aj1_snow_depth"""))

display(sqlContext.sql("""
SELECT
  origin_aa1_rain_depth,
  SUM(dep_del15) / COUNT(*) as pct_delays
FROM joined
GROUP BY origin_aa1_rain_depth
ORDER BY origin_aa1_rain_depth"""))

# COMMAND ----------

# MAGIC %md
# MAGIC As we can see from the above distributions these features appear to have strong correlations with departure delays and will be useful in our models.

# COMMAND ----------

# MAGIC %md
# MAGIC #### Weather Correlation Matrix

# COMMAND ----------

# MAGIC %md
# MAGIC Before we utilize the weather features in our models we wanted to understand if certain variables are highly correlated.  As shown the correlation matrix below the air temperature and dew point temperature have a high correlation above .5.  As a result, we will only include one of these features in the models we build to prevent greater variance in our model coefficients.  

# COMMAND ----------

#Set Path for one hot encoded files
final_project_path = "dbfs:/mnt/mids-w261/group_5/"
dbutils.fs.mkdirs(final_project_path)
train_data_output_path_one_hot = final_project_path + "training_data_output/train_one_hot.parquet"

# Read in parquet file
train_log = spark.read.parquet(train_data_output_path_one_hot)

#Create dataframe with only weather variables that are integers and drop rows with missing data 
weather_df = train_log.select('origin_WND_speed_rate',"origin_TMP_air_temperature",'origin_CIG_ceiling_height',"origin_DEW_dew_point_temp",'origin_VIS_distance','origin_SLP_sea_level_pressure','origin_aj1_snow_depth','origin_aa1_rain_depth')
weather_df = weather_df.dropna()

# COMMAND ----------

#Create weather feature vector 
assembler_weather = VectorAssembler(inputCols=weather_df.columns,outputCol="features").setHandleInvalid("keep")

df_weather_new = assembler_weather.transform(weather_df)

#Run pearson correlation matrix 
r1 = Correlation.corr(df_weather_new, "features").collect()[0][0]

# COMMAND ----------

corrmatrix = r1.toArray().tolist()
df = spark.createDataFrame(corrmatrix,weather_df.columns)

def plot_corr_matrix(correlations,attr):
    fig=plt.figure(figsize=(10,10))
    ax=fig.add_subplot(111)
    ax.set_title("Correlation Matrix for Weather Attributes", fontsize=20, pad=140)
    ax.set_xticklabels(['']+attr, rotation=90)
    ax.set_yticklabels(['']+attr)
    cax=ax.matshow(correlations,cmap='coolwarm',vmax=1,vmin=-1)
    fig.colorbar(cax,fraction=0.046, pad=0.04)
    plt.show()

plot_corr_matrix(corrmatrix, weather_df.columns)

# COMMAND ----------

# MAGIC %md
# MAGIC With a basic understanding of the features we have to use for our model we will next discuss the various feature engineering techniques we employed to get even more signal out of the provided data.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Feature Engineering

# COMMAND ----------

# MAGIC %md
# MAGIC ####Airline Flight Feature Engineering

# COMMAND ----------



# COMMAND ----------

# MAGIC %md
# MAGIC ####Weather Feature Engineering

# COMMAND ----------

# MAGIC %md
# MAGIC To identify weather patterns the could cause delays, we filtered our training data to look at flights that had a weather delay and did not have a weather delay to understand what types of weather thresholds could be used to created indicator variables.  After reviewing the summary statistics for the weather variables, we decided to create four weather indicator variables to increase the signal we might see from the weather features in our models.  The first feature we created was focused on identifying flights that had very low ceiling height below 2,000.  Per the summary statisitic tables below, the average origin ceiling height for weather delays is 4,000 below the ceiling height for non weather delay flights. Moreover, we also noticed the origin wind speed rate is higher for weather delayed flights so we created an indicator that highlights if wind is above 50.  The last two features we created focused on winter and summer temperature trends.  Per the origin air temperature histograms below, the weather delayed flights had a higher percentage of summer flights with below air temperature values below 0, so we created a indicator variable to identify these types of weather patterns during the summer. 

# COMMAND ----------

#Seperate Weather Delays 
delay_udf = udf(lambda x: 0 if x == None or x <= 15 else 1)
train_log = train_log.withColumn('weather_15_delay_indicator', delay_udf(train_log.weather_delay))

# COMMAND ----------

#Review summary stats for weather delays 
display(train_log.filter(col('weather_15_delay_indicator')==1).select('origin_WND_speed_rate',"origin_TMP_air_temperature",'origin_CIG_ceiling_height',"origin_DEW_dew_point_temp",'origin_VIS_distance','origin_SLP_sea_level_pressure','origin_aj1_snow_depth','origin_aa1_rain_depth').summary())

#Review summary stats for other non-weather delayed flights 
display(train_log.filter(col('weather_15_delay_indicator')==0).select('origin_WND_speed_rate',"origin_TMP_air_temperature",'origin_CIG_ceiling_height',"origin_DEW_dew_point_temp",'origin_VIS_distance','origin_SLP_sea_level_pressure','origin_aj1_snow_depth','origin_aa1_rain_depth').summary())

# COMMAND ----------

summer_months=[5,6,7,8,9,10]
winter_months=[1,2,3,4,11,12]

#Review histogram of air temperatures associated with weather delays (1) and flights with no weather delay (0) during the summer
train_log.filter(~col('month').isin(summer_months)).select('origin_TMP_air_temperature',"weather_15_delay_indicator").display()

# COMMAND ----------

# MAGIC %md
# MAGIC ## Algorithm Exploration

# COMMAND ----------

# MAGIC %md
# MAGIC #### Base Model - Logistic Regression

# COMMAND ----------

# MAGIC %md
# MAGIC Our base model is a logistic regression classification model with a subset of the airline and weather features. We included features to capture seasonality, recent weather patterns at the origin airport, time of day, as well as two engineered features that captured whether a previous flight was delayed and whether the day of the flight was a holiday. During our EDA we identified that dew point and air temp were strongly correlated so we only included air temperature to capture the most recent temperature. When we ran our initial logistic regression model, we observed that the model always predicted that there was no delay due to the imbalance in the dataset with under 20% of flights being delayed. To account for the imbalance of the outcome variable we explored two options for the base model including a weight column that utilizes a balancing ratio and adjusting the threshold for the model to a value closer to the mix of delays to no delays. The threshold was slightly more effective at improving recall for our model than the weighted column so we utilitized the threshold in our base model which is shown below. As we increased the threshold from .18 to .5 we noticed a large drop in recall with an increase in accuracy, we found that a threshold below .2 had good balance of accuracy and recall. The most noticeable improvement in the model accuracy and recall came when we added the previous flight delay feature, which signaled to us that this feature maybe very important to include in future models. Our base model had an accuracy and recall of **XX and XX (Pending Model Updates**). In our next models we explore using a broader set of the features available as well as explore oversampling.

# COMMAND ----------

# MAGIC %md Insert Base Model Performance

# COMMAND ----------

# MAGIC %md
# MAGIC ## Algorithm Implementation

# COMMAND ----------

# MAGIC %md
# MAGIC ## Conclusions

# COMMAND ----------

# MAGIC %md
# MAGIC ## Course Concepts

# COMMAND ----------

